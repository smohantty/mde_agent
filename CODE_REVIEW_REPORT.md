# Code and Architecture Review Report

Generated by: **Codex (GPT-5)**  
Date: **2026-02-17**  
Project: **mde_agent**

## Scope

Detailed review of architecture and runtime behavior with focus on:

- Generic behavior vs hacks for specific skills.
- Support for `tool_calls`, `function_calls`, and MCP server integration.
- Risks, constraints, and implementation gaps.

## Executive Verdict

1. The system has a strong generic foundation for skill loading, routing, and prompt-driven orchestration.
2. It is **not fully generic in behavior** due to a few heuristic paths in core runtime.
3. Native provider `tool_calls`/`function_calls` are **not implemented**.
4. MCP server integration is **not implemented**.

## Architecture Summary

Primary runtime flow:

1. CLI entrypoint receives task (`agent/cli.py`).
2. Orchestrator loads skills, prefilters candidates, and discloses stage-1 context (`agent/runtime/orchestrator.py`).
3. Prompt builder asks model for JSON actions (`agent/llm/prompt_builder.py`).
4. Provider router calls Anthropic/Gemini clients (`agent/llm/provider_router.py`).
5. Decoder normalizes model output to canonical actions (`agent/llm/decoder.py`).
6. Executor runs shell commands and records artifacts (`agent/runtime/executor.py`).
7. Events/transcripts are logged for each call site (`agent/logging/events.py`, `agent/logging/transcript.py`).

Core canonical actions:

- `run_command`
- `call_skill`
- `ask_user`
- `finish`

Declared in `agent/types.py:8`.

## Findings (Severity Ordered)

### High 1: Cross-skill alias/default leakage in decoder

The decoder falls back to alias/default maps from *all* skills when selected-skill mapping misses.

Impact:

- One skill can influence action decoding for another skill.
- Behavior becomes non-deterministic at scale with more skills.

Evidence:

- `agent/llm/decoder.py:95`
- `agent/llm/decoder.py:119`

### High 2: Native provider tool/function calling is not implemented

Provider clients use text prompt -> JSON parse flow only.

Impact:

- No native provider tool schema enforcement.
- More brittle than provider-native function/tool invocation paths.

Evidence:

- `agent/llm/anthropic_client.py:26`
- `agent/llm/gemini_client.py:26`
- `agent/llm/structured_output.py:30`
- `agent/llm/prompt_builder.py:36`

### High 3: MCP server support is absent

No MCP discovery/call layer exists in runtime, LLM, or tool execution paths.

Impact:

- Cannot integrate MCP tool ecosystems.
- Cannot perform MCP-backed context/tool calls.

Evidence:

- No MCP implementation files under `agent/`.
- No MCP runtime references found in `agent/`, `docs/`, or `tests/`.

### Medium 1: `call_skill` is mostly logical signaling, not delegated execution

`call_skill` records handoff intent but does not execute a separate delegated skill runtime.

Impact:

- “Skill call” semantics can be misleading.
- Multi-skill delegation remains prompt-loop driven, not runtime delegation.

Evidence:

- `agent/runtime/orchestrator.py:910`
- `agent/runtime/orchestrator.py:1425`

### Medium 2: `allowed_tools` is parsed but not enforced at execution boundary

Skill metadata includes `allowed_tools`, but runtime does not block disallowed action types.

Impact:

- Model can emit actions outside skill-declared tool policy.
- Weakens skill contract as a safety/control boundary.

Evidence:

- Parsed: `agent/skills/parser.py:84`
- Propagated to prompt catalog: `agent/runtime/orchestrator.py:159`
- No enforcement before execution path: `agent/runtime/orchestrator.py:825`

### Medium 3: Core runtime includes markdown-specific heuristics

Runtime rewrites commands and recovery logic with markdown-oriented assumptions.

Impact:

- Non-markdown workloads may be shaped by unrelated heuristics.
- Reduces strict skill-agnostic behavior.

Evidence:

- `agent/runtime/orchestrator.py:167`
- `agent/runtime/orchestrator.py:196`
- `agent/runtime/orchestrator.py:296`

### Low 1: Stage-3 disclosure is implemented but not used by orchestrator

Disclosure engine has stage-3 script descriptors, but orchestration path only uses stage-1/stage-2.

Impact:

- Architecture/docs imply fuller progressive disclosure than runtime currently applies.

Evidence:

- Stage-3 definition: `agent/skills/disclosure.py:72`
- Runtime usage path: `agent/runtime/orchestrator.py:1064`, `agent/runtime/orchestrator.py:1428`

### Low 2: `ask_user` is non-interactive and always skipped

Runtime marks `ask_user` actions as skipped in non-interactive mode.

Impact:

- True interactive clarification loop is not available in current runtime behavior.

Evidence:

- `agent/runtime/orchestrator.py:935`

## Genericity Assessment

What is generic and strong:

1. Dynamic skill discovery by folder + `SKILL.md`.
2. Fuzzy prefilter routing based on metadata.
3. Provider abstraction via `ProviderRouter`.
4. Canonical action normalization and structured transcript logging.

What is not fully generic:

1. Cross-skill fallback in decoder alias/default lookup.
2. Markdown-focused command/recovery heuristics in core runtime.
3. Missing enforcement for declared tool constraints.

No direct hardcoded branches keyed by specific demo skill names were found in orchestrator/decoder paths.

## Capability Matrix

| Capability | Status | Notes |
|---|---|---|
| Internal `tool_call` classification | Implemented | Classification label is derived from canonical actions (`run_command`) in transcripts/events. |
| Provider-native `tool_calls` | Not implemented | No native tool schema declarations in Anthropic/Gemini clients. |
| Provider-native `function_calls` | Not implemented | No function declaration/invocation protocol in provider clients. |
| MCP server integration | Not implemented | No MCP client/session/tool wiring in runtime. |
| Generic skill loading/routing | Implemented | Data-driven via parser/registry/router. |

## Additional Notes

Quality gates currently pass in this repo state:

- `uv run pytest` -> 56 passed
- `uv run ruff check .` -> pass
- `uv run pyright` -> 0 errors

This indicates stable current behavior, but does not remove the architectural gaps listed above.

## Prioritized Recommendations

1. Fix decoder isolation so alias/default lookup only resolves within selected skill unless explicit global policy is defined.
2. Add runtime enforcement for `allowed_tools` at action execution boundary.
3. Introduce provider-native tool/function calling mode behind config flag, preserving current JSON fallback for compatibility.
4. Add MCP integration as a separate tool provider layer (discovery, invocation, result normalization).
5. Remove markdown-specific heuristics from core runtime and relocate them into optional skill metadata/policies.
6. Implement interactive `ask_user` handling or replace with explicit fail-fast semantics.
7. Wire stage-3 disclosure into orchestrator if script descriptors are part of intended runtime contract.

## Final Answer To Requested Questions

1. Are there hacks to make some skills work?
   - No explicit hardcoded skill-name hacks were found.
   - Yes, there are heuristic behaviors in core runtime that are not fully skill-agnostic.

2. Is it generic for any skills and tool/function calls?
   - Generic for skill loading/routing: mostly yes.
   - Generic for provider-native `tool_calls` / `function_calls`: no, not currently implemented.

3. Is MCP server support present?
   - No, MCP support is not implemented in this codebase.

